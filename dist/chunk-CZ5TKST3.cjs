'use strict';

var chunk57AVKP4H_cjs = require('./chunk-57AVKP4H.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');

var oe={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0,onProcessAudioChunk:void 0},ae={stop:void 0},ie={blob:void 0,text:void 0},pe=_=>{let{apiKey:f,autoStart:v,autoTranscribe:C,mode:y,nonStop:U,removeSilence:L,stopTimeout:M,streaming:h,timeSlice:q,whisperConfig:u,onDataAvailable:K,onTranscribe:O,onProcessAudioChunk:S}={...oe,..._};if(!f&&!O&&!S)throw new Error("apiKey is required if onTranscribe is not provided");let d=react.useRef([]),i=react.useRef(),s=react.useRef(),r=react.useRef(),o=react.useRef(),l=react.useRef(ae),[I,T]=react.useState(!1),[$,B]=react.useState(!1),[j,m]=react.useState(!1),[z,k]=react.useState(ie);react.useEffect(()=>()=>{d.current&&(d.current=[]),i.current&&(i.current.flush(),i.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),g("stop"),s.current&&(s.current.off("speaking",R),s.current.off("stopped_speaking",A)),o.current&&(o.current.getTracks().forEach(e=>e.stop()),o.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{v&&await W();},[v]);let N=async()=>{await W();},G=async()=>{await V();},J=async()=>{await E();},W=async()=>{try{if(o.current||await Q(),o.current){if(!r.current){let{default:{RecordRTCPromisesHandler:t,StereoAudioRecorder:a}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:a,sampleRate:44100,timeSlice:h?q:void 0,type:"audio",ondataavailable:C&&h?Z:void 0};r.current=new t(o.current,n);}if(!i.current){let{Mp3Encoder:t}=await import('lamejs');i.current=new t(1,44100,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),U&&x("stop"),T(!0);}}catch{}},Q=async()=>{try{if(o.current&&o.current.getTracks().forEach(e=>e.stop()),o.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(o.current,{interval:100,play:!1}),s.current.on("speaking",R),s.current.on("stopped_speaking",A);}}catch{}},x=e=>{l.current[e]||(l.current[e]=setTimeout(E,M));},R=()=>{B(!0),g("stop");},A=()=>{B(!1),U&&x("stop");},V=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),g("stop"),T(!1));}catch{}},E=async()=>{try{if(r.current){let e=await r.current.getState();if((e==="recording"||e==="paused")&&await r.current.stopRecording(),X(),g("stop"),T(!1),C)await Y();else {let t=await r.current.getBlob();k({blob:t});}await r.current.destroy(),d.current=[],i.current&&(i.current.flush(),i.current=void 0),r.current=void 0;}}catch{}},X=()=>{s.current&&(s.current.off("speaking",R),s.current.off("stopped_speaking",A),s.current=void 0),o.current&&(o.current.getTracks().forEach(e=>e.stop()),o.current=void 0);},g=e=>{l.current[e]&&(clearTimeout(l.current[e]),l.current[e]=void 0);},Y=async()=>{try{if(i.current&&r.current&&await r.current.getState()==="stopped"){m(!0);let t=await r.current.getBlob();if(L){let{createFFmpeg:a}=await import('@ffmpeg/ffmpeg'),n=a({mainName:"main",corePath:chunk57AVKP4H_cjs.b,log:!0});n.isLoaded()||await n.load();let c=await t.arrayBuffer();n.FS("writeFile","in.wav",new Uint8Array(c)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",chunk57AVKP4H_cjs.c,"out.mp3");let b=n.FS("readFile","out.mp3");if(b.length<=225){n.exit(),k({blob:t}),m(!1);return}t=new Blob([b.buffer],{type:"audio/mpeg"}),n.exit();}else {let a=await t.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(a));t=new Blob([n],{type:"audio/mpeg"});}m(!1);}}catch{m(!1);}},Z=async e=>{try{if(h&&r.current){if(K?.(e),i.current){let a=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(a)),c=new Blob([n],{type:"audio/mpeg"});d.current.push(c);}if(await r.current.getState()==="recording"){let a=new Blob(d.current,{type:"audio/mpeg"}),n=new File([a],"speech.mp3",{type:"audio/mpeg"}),c="";typeof S=="function"?c=await S(n):f&&(c=await ee(n)),c&&k(b=>({...b,text:c}));}}}catch{}},ee=reactHooksAsync.useMemoAsync(async e=>{let t=new FormData;t.append("file",e),t.append("model","whisper-1"),y==="transcriptions"&&t.append("language",u?.language??"en"),u?.prompt&&t.append("prompt",u.prompt),u?.response_format&&t.append("response_format",u.response_format),u?.temperature&&t.append("temperature",`${u.temperature}`);let a={};a["Content-Type"]="multipart/form-data",f&&(a.Authorization=`Bearer ${f}`);let{default:n}=await import('axios');return (await n.post(chunk57AVKP4H_cjs.d+y,t,{headers:a})).data.text},[f,y,u]);return {recording:I,speaking:$,transcribing:j,transcript:z,pauseRecording:G,startRecording:N,stopRecording:J}};

exports.a = pe;
